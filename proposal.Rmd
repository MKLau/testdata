---
title: "Project Proposal"
output:
     html_document
---

__Proposal Deadline: Jan 30, 2017 11:59pm__


- Edit this markdown file by __replacing only__ what is there in the
chunks named `q0`, `q1`, `q2`, ..., `q5` with your team's appropriate
answers. These chunks have been filled in as an example.

- Place the filled in markdown in any one of the team member's private
directory with the same name `proposal.Rmd`. Do not change the name!


0. Who are the authors of this package? See format below.

```{r q0}
authors <- list(jpeach = "John Peach",
                mcampos = "Marilson Campos",
                ptelukun = "Prasad Telukuntla")
```

1. What is your package trying to achieve?  Who is it aimed at?

```q1
Best practices for data analysis require that the Data Scientist perform a series of steps to clean the data and in doing so shape the data into a known form and state. This is often a time consuming and manual process. After this is done the Data Scientist begins the exploration phase of the analysis and often discovers further cleaning that must be performed.  As new data is added or a new data set replaces the old the entire process must be repeated. This creates concerns that the shape, nature and form of the data my not be consistent from one analysis to the next

Software developers have a similar issue when it comes to validating their code. Once a unit of code has been written it must be validated to confirm that it performing as expected. Data Scientists must validate that their data is also in the shape, nature and form as they understand it. While the shaping, forming and understanding the nature is generally done in the cleaning phase it is rare to perform formal validation.

The goal of this package is to develop a set of tools/framework that validates the cleaned data. It uses a unit testing approach that are familiar to many Data Scientists and software developers. It extends the popular testthat package by adding tests that are specific to validating data and also vectorizing existing tests. This approach allows the Data Scientist to test the assumptions that they make on the data by ensuring that the shape, statistical characteristics, data types, column and row names are defined as expected. 

In doing so, it increases the confidence that nothing has been missed when a data file is used and reduces the amount of re-analysis that is performed because the data was not cleaned properly, violated statistical assumptions or stored incorrectly in data structures. In doing this, when data is added or a replacement data set is used, there is a greater degree of confidence that the data is well conditioned and at the same time reducing the need for time consuming need to manually recheck the data after cleaning.

The testdata package is aimed at Data Scientists, Analysts and Data Engineers in any industry or academic field. It is a generalized tool to aid in the reproducibility of results and formalizing the technical steps in the analysis process.

```

2. Briefly describe the background if that's not obvious.  What field
   or area of interest is it related to?  (Just briefly, in a paragraph
   or two, maximum.) References, including web references, are welcome
   where available.

```q2
This package is inspired by the "Unit testing" technique, where additional code ('test code'), is written to 
validate parts of the application against a set of rules ('test cases.')

These tests are then used to report errors as changes to the program will make it produce results that violate 
the rules defined in test cases. 

We apply the same idea to the 'data,' where we define 'data test cases' and validate the dataset using these 
rules.

References:
A tool to perform tests on data: 
https://www.import.io/post/how-to-test-the-quality-of-web-data/

Unit testing in R:  Hadley Wickham's package testthat. 
http://r-pkgs.had.co.nz/tests.html
github: (https://github.com/hadley/testthat)```
```
3. Provide one or two use cases; that is, in a sentence or so say how
   you see someone using the package.


```q3
In reproducible research, we execute a 'data cleaning' step followed by the steps unique to the research.

Data Scientists can use this tool to add a new 'data validation' step after the 'data cleaning' step. In 
this 'data validation' step, we look at the data profile and define rules ('assumptions') about the data.

Next time that we process a new 'version' of the dataset, we can verify that these assumptions about the
data are still valid. 

Here are some examples of verifications:  
1. factor 'state' has 50 levels, and each level has values.
2. field 'age' has median between 17 - 35 years old.
3. field 'age' has no record with a value larger than 55 years.

```

4. If you can, list the main functions or other software you plan on
   including.  No need to implement anything now, but you should have
   an idea.

```q4
The main function will be defined as verify(data_tests, data). This function will load 'data test' 
definitions and validate them against the data frame provided.

Each verification will either pass of generate a 'report' explaining what failed.

There will be a family of functions starting with 'is_' that will test a column of the  data frame 
against a constraint. 

Here are some of examples: 
  'is_within_abs_tolerance', 'is_within_percent_tolerance', etc.

The data test cases will be defined using functions of the form 'verify_data(description, code)' 
in a similar way of the 'test_that' function from the testthat package.

We are including the package 'testthat' in our 'testdata' package.
```

```{r, echo = FALSE, hide = TRUE}
none <- "none"
basic <- "basic"
proficient <- "proficient"
```

5. For languages C/C++, Java, Python, Ruby, please specify your
   proficiency: Proficient, basic knowledge, no knowledge.  (This
   helps us evaluate the proposal sometimes and offer suggestions.)

```{r q5}
languages <- list(
    ## replace the values below appropriately for each member
    jpeach = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
    ,
    mcampos = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
    ,
    ptelukun = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
)
```








