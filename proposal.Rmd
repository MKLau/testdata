---
title: "Project Proposal"
output:
     html_document
---

__Proposal Deadline: Jan 30, 2017 11:59pm__


- Edit this markdown file by __replacing only__ what is there in the
chunks named `q0`, `q1`, `q2`, ..., `q5` with your team's appropriate
answers. These chunks have been filled in as an example.

- Place the filled in markdown in any one of the team member's private
directory with the same name `proposal.Rmd`. Do not change the name!


0. Who are the authors of this package? See format below.

```{r q0}
authors <- list(jpeach = "John Peach",
                mcampos = "Marilson Campos",
                ptelukun = "Prasad Telukuntla")
```

1. What is your package trying to achieve?  Who is it aimed at?

```q1
Best practices for data analysis require that the Data Scientist perform a series of steps to clean the data and in doing so shape the data into a known form and state. This is often a time consuming and manual process. After this is done the Data Scientist begins the exploration phase of the analysis and often discovers further cleaning that must be performed.  As new data is added or a new data set replaces the old the entire process must be repeated. This creates concerns that the shape, nature and form of the data my not be consistent from one analysis to the next

Software developers have a similar issue when it comes to validating their code. Once a unit of code has been written it must be validated to confirm that it performing as expected. Data Scientists must validate that their data is also in the shape, nature and form as they understand it. While the shaping, forming and understanding the nature is generally done in the cleaning phase it is rare to perform formal validation.

The goal of this package is to develop a set of tools/framework that validates the cleaned data. It uses a unit testing approach that are familiar to many Data Scientists and software developers. It extends the popular testthat package by adding tests that are specific to validating data and also vectorizing existing tests. This approach allows the Data Scientist to test the assumptions that they make on the data by ensuring that the shape, statistical characteristics, data types, column and row names are defined as expected. 

In doing so, it increases the confidence that nothing has been missed when a data file is used and reduces the amount of re-analysis that is performed because the data was not cleaned properly, violated statistical assumptions or stored incorrectly in data structures. In doing this, when data is added or a replacement data set is used, there is a greater degree of confidence that the data is well conditioned and at the same time reducing the need for time consuming need to manually recheck the data after cleaning.

The testdata package is aimed at Data Scientists, Analysts and Data Engineers in any industry or academic field. It is a generalized tool to aid in the reproducibility of results and formalizing the technical steps in the analysis process.

```

2. Briefly describe the background if that's not obvious.  What field
   or area of interest is it related to?  (Just briefly, in a paragraph
   or two, maximum.) References, including web references, are welcome
   where available.

```q2

This package is a framework and applicable to most of the domains. Following is the scope of testdata validation framework.

1) Validate list of dataframes
2) Validate the Model objects (lm, GLM etc)
3) Validate list of row names
4) Validate list of all column names
5) Validate All factors present for a set of columns
6) Valdiate for a given set of values present in specified columns
7) Valdiate if all values are present for a set of columns
8) Validate if a particular column is Ascending order or Descending order
9) Metric (Mean, sum, standard deviation etc) are within a range
10) Custom Metric (with extra parameters for computing it) within a range
11) Expected Number of factors
12) All factors exit
13) Detecting Outliers based on the definition
14) Checking for Greater than, Greater than or equal, Less than and Less than or equal
15) Columns Floor and Ceiling
16) Test for normalcy
17) Vignette documenation of each of the use case


This package is inspired by the Hadley Wickham's package testthat. 
github: https://github.com/hadley/testthat
Reference: http://r-pkgs.had.co.nz/tests.html

```

3. Provide one or two use cases; that is, in a sentence or so say how
   you see someone using the package.

```q3

Data Scientists once they complete the model, they can run this pacakge on the new dataset that comes in to check if the data validation is passed before performing final prediction. This can also work as Monitorting component in the production pipeline. As data validation is hard and only Data Scientist can help define that through this pacakage.



```

4. If you can, list the main functions or other software you plan on
   including.  No need to implement anything now, but you should have
   an idea.

```q4

The R package will provide the following functions: reading and
writing data, creating graphs and visualizations, running
parameterized queries against datasets.  The R package will also
provide functions for generating vignette and report on the test results.

```

```{r, echo = FALSE, hide = TRUE}
none <- "none"
basic <- "basic"
proficient <- "proficient"
```

5. For languages C/C++, Java, Python, Ruby, please specify your
   proficiency: Proficient, basic knowledge, no knowledge.  (This
   helps us evaluate the proposal sometimes and offer suggestions.)

```{r q5}
languages <- list(
    ## replace the values below appropriately for each member
    jpeach = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
    ,
    mcampos = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
    ,
    ptelukun = c(cxx = proficient,
               java = proficient,
               python = proficient,
               ruby = none)
)
```








